---
layout: post
title: How to Prevent Human Extinction
permalink: /agi/
date: 2020-10-27
---

Sometimes you come across common threads in unexpected, disparate places. I was listening to the [Alignment Newsletter Podcast](https://alignment-newsletter.libsyn.com/) when I came across the idea that artificial intelligence safety is a [many-to-many problem](https://alignment-newsletter.libsyn.com/alignment-newsletter-118) with many AI and human agents. This idea is further explored in [The Age of Em](http://ageofem.com/).

Then I listened to the audiobook version of [Deep Survival](https://www.amazon.com/Deep-Survival-Who-Lives-Dies/dp/0393326152) and learned about disaster siatuations in complex systems. That got me to think more about disasters - more than I [already](/quality-march-2019) did - and to try to tie it together in some way, since disasters are in everyone's radar these days. 

What allowed me to wrap my head around disaster prevention is by reading the book [Engineering a Safer World](https://mitpress.mit.edu/books/engineering-safer-world) which tackles safety-critical engineering from a systems perspective. It provides a theoretical yet practical guideline on how to analyze and prevent disasters in complex systems. 

Finally, I played the game [Tacoma](https://tacoma.game/), a sci-fi exploration game which featured a disaster scenario exacerbated by AI. It seemed like the perfect case study in a time where real disaster case studies would be too depressing. 

I weaved together these tangentially related threads in an [op-ed](http://www.campustimes.org/2020/10/25/disaster-prevention-lessons-from-ai/) for the University of Rochester student newspaper [Campus Times](http://www.campustimes.org/). I am thrilled that it somehow managed to come out as a cohesive article after weeks of research, writing, and the editor's wordsmithing.

# Bibliography

[1] Fullbright Games. 2016. Tacoma. Retrieved from [https://tacoma.game](https://tacoma.game)

[2] Katja Grace, John Salvatier, Allan Dafoe, Baobao Zhang, and Owain Evans. 2017. [When Will AI Exceed Human Performance? Evidence from AI Experts.](https://arxiv.org/abs/1705.08807) Arxiv (2017).

[3] Rohin Shah. [AN #118]: Risks, solutions, and prioritization in a world with many AI systems. Alignment Newsletter. Retrieved October 5, 2020 from [https://mailchi.mp/d0b668319344/an-118risks-solutions-and-prioritization-in-a-world-with-many-ai-systems](https://mailchi.mp/d0b668319344/an-118risks-solutions-and-prioritization-in-a-world-with-many-ai-systems)

[4] Eliezer Yudkowsky. AI Alignment: Why Itâ€™s Hard, and Where to Start. Machine Intelligence Research Institute. Retrieved October 20, 2020 from [https://intelligence.org/2016/12/28/ai-alignment-why-its-hard-and-where-to-start/](https://intelligence.org/2016/12/28/ai-alignment-why-its-hard-and-where-to-start/)

[5] Robert Miles, Computerphile. 2017. AI? Just Sandbox it... Youtube. Retrieved October 20, 2020 from [https://www.youtube.com/watch?v=i8r_yShOixM](https://www.youtube.com/watch?v=i8r_yShOixM)

[6] Robin Hanson. 2016. The Age of Em. Oxford University Press. Retrieved from [ageofem.com](ageofem.com)

[7] Nancy G Leveson. 2012. Engineering a Safer World: Systems Thinking Applied to Safety. MIT Press. Retrieved October 4, 2020 from [https://mitpress.mit.edu/books/engineering-safer-world](https://mitpress.mit.edu/books/engineering-safer-world)
